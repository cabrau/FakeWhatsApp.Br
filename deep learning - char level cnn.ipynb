{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Convolutional Network\n",
    "In this notebook we train and evaluate the performance of a convolutional neural network in the task of detecting misinformation in WhatsApp texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE \n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cabral/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>ddi</th>\n",
       "      <th>country</th>\n",
       "      <th>country_iso3</th>\n",
       "      <th>ddd</th>\n",
       "      <th>state</th>\n",
       "      <th>group</th>\n",
       "      <th>midia</th>\n",
       "      <th>url</th>\n",
       "      <th>characters</th>\n",
       "      <th>words</th>\n",
       "      <th>viral</th>\n",
       "      <th>sharings</th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3631133147603888180</td>\n",
       "      <td>01/08/18</td>\n",
       "      <td>13:13</td>\n",
       "      <td>55</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>BRA</td>\n",
       "      <td>17</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>2018_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;Arquivo de mídia oculto&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3631133147603888180</td>\n",
       "      <td>01/08/18</td>\n",
       "      <td>13:24</td>\n",
       "      <td>55</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>BRA</td>\n",
       "      <td>17</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>2018_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>O Bolsonaro tem que estar preparado pra respon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3631133147603888180</td>\n",
       "      <td>01/08/18</td>\n",
       "      <td>13:24</td>\n",
       "      <td>55</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>BRA</td>\n",
       "      <td>17</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>2018_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;Arquivo de mídia oculto&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4391661641377612003</td>\n",
       "      <td>01/08/18</td>\n",
       "      <td>13:28</td>\n",
       "      <td>55</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>BRA</td>\n",
       "      <td>13</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>2018_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Boaaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4391661641377612003</td>\n",
       "      <td>09/08/18</td>\n",
       "      <td>14:46</td>\n",
       "      <td>55</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>BRA</td>\n",
       "      <td>13</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>2018_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;Arquivo de mídia oculto&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      date   hour ddi country country_iso3 ddd  \\\n",
       "0  3631133147603888180  01/08/18  13:13  55  BRASIL          BRA  17   \n",
       "1  3631133147603888180  01/08/18  13:24  55  BRASIL          BRA  17   \n",
       "2  3631133147603888180  01/08/18  13:24  55  BRASIL          BRA  17   \n",
       "3 -4391661641377612003  01/08/18  13:28  55  BRASIL          BRA  13   \n",
       "4 -4391661641377612003  09/08/18  14:46  55  BRASIL          BRA  13   \n",
       "\n",
       "       state   group  midia  url  characters  words  viral  sharings  \\\n",
       "0  São Paulo  2018_1      1    0          25      4      0         1   \n",
       "1  São Paulo  2018_1      0    0          58      9      1         2   \n",
       "2  São Paulo  2018_1      1    0          25      4      0         1   \n",
       "3  São Paulo  2018_1      0    0           5      1      0         1   \n",
       "4  São Paulo  2018_1      1    0          25      4      0         1   \n",
       "\n",
       "                                                text  misinformation  \n",
       "0                          <Arquivo de mídia oculto>               0  \n",
       "1  O Bolsonaro tem que estar preparado pra respon...               0  \n",
       "2                          <Arquivo de mídia oculto>               0  \n",
       "3                                              Boaaa               0  \n",
       "4                          <Arquivo de mídia oculto>               0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 2018\n",
    "filepath = 'data/' + str(base) + '/fakeWhatsApp.BR_' + str(base) + '.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "#texts\n",
    "texts = df[df['midia']==0]['text']\n",
    "#target\n",
    "y = df[df['midia']==0]['misinformation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char vocabulary, encoding and decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304\n"
     ]
    }
   ],
   "source": [
    "txt_list = list(texts)\n",
    "txt_str = \" \".join(txt_list)\n",
    "#word_list = msg_str.split()\n",
    "char_list = list(txt_str)\n",
    "vocab_set = set(char_list)\n",
    "features = len(vocab_set)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠒ 🅱 🕴 н 😆 🍚 🃏 ໊ 😫 🔞 🤰 実 💮 📏 ル 😱 ⣙ じ 😠 ┗ 🚍 分 🇪 🐇 🗞 🐴 ] 🧚 喜  ⠁ 🚀 🚢 T 🖖 🐓 と ・ ✓ 🗣 🗻 💽 📚 ☆ ま ⢠ ⚫ 🆘 式 🔨 👴 🅰 🍬 ້ 🥁 ー ◇ ❄ 7 🐺 💅 🍳 🍌 📰 z り 🤕 l ☹ 🍞 の 😌 🔬 💢 💠 ৣ 🗯 ⛪ 】 🎫 〽 🇱 ↪ ঔ 🏀 🌪 ═  🤛 > 😁 ⭐ 💉 6 🏩 % た 💡 🤺 🌛 🚖 🌝 🔝 ✋ א 🤒 🇳 \\ ┏ 🦇 ט 😥 „ 🐠 介  午 🍤 ⣼ а χ 🐎 á 🌻 😣 🐛 ­ 🍵 わ 何 🤧 D 🍆 🛵 🛎 ツ ο 🛐 ┻ ⠉ 👢 【 🍏 ά 🕔 正 ë ♠ 🚲 ⚓ 😘 ¬ Ã 🤵 🆙 ⏹ 持 🖐 ⣉ 📩 🌟 😋 ⚔ 💷 💺 🤮 ┃ 📉 😽 ☝ ɴ 🇫 h ‿ 🐸 🚑 ☺ 🇾 ♀ 👦 示 😬 🤐 _ 🌜 ⤴ 🗓 ☃ 卐 🏼 🥑 🚗 Í 👽 ⡟ 👙 💕 🎤 👐 📺 C 🍷 場 ່ 🌱 ➖ 🇴 🎊 🤳 🔹 » 🆖 ב 🏋 ģ 👻 🏴 Ä U ∴ で 🐱 k 🌽 � 😜 🛸 ” 🐗 ◤ 🤗 🌨 🍎 🤱 ► 🤹 🚮 L B 🚬 Ă ¤ 💲 ė 😉 🦅 ヘ 🎁 😙 🤯 🐽 . 🚛 🎵 ⣆ 📱 🏳 🦋 👹 一 ¡ 🚤 🎥 # λ 🍛 υ 😐 ヽ 📦 💝 👸 😲 ⚽ * 🚦 φ Ɨ ❎ 😵 🍦 ◥ ╭ ☞ 💰 👆 s 🥘 È ⣦ 😧 🍾 ⛴ 🚉 Ƭ お 🔟 😇 Z + 🕑 ̈ 💵 ⡛ 🥛 第 ➤ 📜 🏨 😻 幺 🍯 🎖 🎋 🔺 👉 📖 ⃣ ⠿ ɨ 😗 ◀ 📗 🙇 👰 を 🙌 ☕ 🔮 🙃 🌴 🐦 ι τ 😝 🍄 ⎠ g 👊 ■ G — ➜ т ⠙ 🎩 ή 🖍 M 😼 🌞 🛏 ╱ 🆗 📆 😅 🛩 ) ⁩ ⠟ ┣ d 🤔 ̲ 🧔 🐖 9 ĺ 🍼 🧡 🏞 : 🥚 🎙 🍒 🗑 😶 ┛ ✏ 💃 🐀 🌕 🎨 🔕 📵 c 🤫 🐌 🏹 🔋 ╰ 👵 ⡋ ▪ ⠀ 🔈 ─ 🌭 る ❌ \n",
      " 🔔 🙆 🕵 🇰 👼 η ⠢ ✍ 👮 🚡 ̷ j 💬 ê 🏥 🚜 ┳ 💣 ✌ ⣸ 🦀 👿 × 📝 🔩 e  ",
      " 💓 🎾 ⣾ 🎅 📢 ⚠ 🧐 ✿ 🇺 🛴 ⏬ ύ 🇷 っ ⠋ Ô 🧜 📷 H 🐢 定 💒 ⣭ 👠 ໋ 🤼 à ⣤ 🚒 🛇 💥 ケ 📛 🤚 ⚒ \t 👨 ポ ♥ ⚰ 🍰 警 Ç 👘 💘 🚈 😎 😯 🙊 📐 🇼 · 👀 ☄ 🇵 🎻 ╯ 🧟 ☻ 📙 ⎝ ⏩ 🔴 ÷ « ^ ✨ ï 📴 💛 🌧 Å ❤ ⢿ ` 💀 🦕 🍣 😡 🔃 − ù A 📕 🚊 ‒ R ν 🌎 🕚 🌈 § ä р = W 🛡 ø 🥧 ​ ķ 😮 😪 ⛸ ➰ 🎆 - 👳 ö ü 🤴 🇹 ⛏ u ⛽ ñ 📬 ✠ 😭 ❇ ε 🍻 a   🤜 😤 🤲 🌵 🚐 1 😰 😚 🍍 🇯 💔 🤞 ▀ ス 🕊 🦐 🛫 🎼 🔖 🔽 🌼 ′ Ě 😴 👂 😍 🚘 🔛 🍙 🐟 🎀 🕓 🍽 0 🧠 📣 🇲 👁 🖊 、 🌀 Y 可 🏻 ⚖ 🐰 👥 😀 f 💞 3 🇩 🍐 🏃 紹 ⡻ 👎 💪 😛 🐂 👋 ⬇ ♏ ļ ō 👇 ▄ 🛥 前 😖 ' 🦑 ç 厂 ⢸ 🛰 🥊 ━ 💈 ╚ ິ Į 🌊 🖋 🍟 ⠐  🎶 I ◾ ╝ ⛷ Ü 😕 🤷 < 👶  ̄ 《 ô 証 🌾 🚩 🎽 † 🍉 🍀 🚚 🔱 📘 🍖 🍂 🤙 ◣ 入 🎬 ✖ 三 🎞 🤟 🌍 🔰 ⢲ ‭ 💩 🛌 2 😒 🏫 ↘ ￿ 👏 ⏲ ⣄ ú 🌉 ✴ 🎹 い 👬 ā S 🕯 💟 か X 宣 δ 要 🍕 💭 🚂 O μ 🎧 8 💯 私 🚁 ď 🐝 🚹 🇬 🐶 》 £ ❪ Α 🌿 ⚜ ό 🐤 💙 œ 🎸 | ➡ 🤘 🐮 🧢 , グ 🍿 🍁 / ◡ 👪 👣 @ 藤 🌏 🕗 れ 📹 🎚 な 🛳 ʖ ⡿ 🧑 â 🅿  😩 y ⣠ í 🇿 ❗ ♦ V 🎷 🙈 ▫ 関 😷 🚎 🕥 👫 🚵 י 🌐 θ 🚴 ⛑ ⚙ ( t 💚 ã ¿ 捜 🔑 🏆 ⛅ ❓ づ 🥣 💍 🌤 🕐 w  💦 🆓 ᒪ 🐥 🚷 ☔ 💤 Á 🏅 👷 🍸 🍩 💊 🐁 🕕 ⣴ ò › 🍱 ⠸ ‘ 💂 🚄 ⬅ 🍢 ີ 🏽 🗨 🏍 は 🌷 🗳 p ┫ π ⣷ ‌ 🔫 ! 🌫 😂 ⠂ 😾 ☁ q ó 💳 🔜 ̤ 👟 〰 力 ‏ ì i 🤸 🎂 🍮 🍹 ̿ ↖ 🥙 ⠛ イ 者 ш 🤖 🥂 ⬆ ́ 👧 ✊ 👈 ® 🐭 ⛱ 🛑 🌅 🥤 Â ⛓ E 💨 ᘉ $ 🎇 📈 😹 😏 ✝ 🏚 🔸 🏷 ◆ 🖌 🌹 ⠻ 👔 ⠃ 🦆 🍃 す K ☎ 🌌 N b 👱 "
     ]
    }
   ],
   "source": [
    "for v in list(vocab_set):\n",
    "    print(v, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaries to encode char to indexes and indexes to char\n",
    "char2Code = {}\n",
    "code2Char = {0: ''}\n",
    "\n",
    "i=1\n",
    "for char in list(vocab_set):\n",
    "    char2Code[char] = i\n",
    "    code2Char[i] = char\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 173, 1251, 287, 952, 1251, 287, 952, 951, 952, 1181, 427, 287, 1181, 1235, 1235, 1235, 952, 341, 617, 1181, 386, 173, 951, 576, 952, 102]\n",
      "This is a test!!! Gotcha? 🌝\n"
     ]
    }
   ],
   "source": [
    "#enconding and decoding fu\n",
    "def vectorize(text, char2Code = char2Code):\n",
    "    '''\n",
    "    Enconding function: converts an string in code\n",
    "    Input: string\n",
    "    Output: coded string\n",
    "    '''\n",
    "    #text = text.lower()\n",
    "    text_list = list(text)\n",
    "    text_vector = []\n",
    "    for token in text_list:\n",
    "        if token in char2Code:\n",
    "            code = char2Code[token]\n",
    "            text_vector.append(code)\n",
    "        else:\n",
    "            text_vector.append(0)\n",
    "    return(text_vector)\n",
    "\n",
    "def unvectorize(vec, code2Char = code2Char):\n",
    "    '''\n",
    "    Decoding function: converts code in string\n",
    "    Input: coded index list\n",
    "    Output: string\n",
    "    '''\n",
    "    text = ''\n",
    "    for i in vec:\n",
    "        text += code2Char[i]\n",
    "    return text\n",
    "        \n",
    "v = vectorize('This is a test!!! Gotcha? 🌝')\n",
    "w = unvectorize(v)\n",
    "print(v)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vec'] = [vectorize(x) for x in df['text']]\n",
    "X = df['vec'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114445,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuition of chars in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4d578d8908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df['characters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    114445.000000\n",
       "mean        135.869675\n",
       "std         515.457870\n",
       "min           1.000000\n",
       "25%          21.000000\n",
       "50%          40.000000\n",
       "75%          94.000000\n",
       "max       65536.000000\n",
       "Name: characters, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['characters'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [114445, 114444]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-9aeeb511e5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2125\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [114445, 114444]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80110,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 911,  386,  951, 1303,  617,  942,  942,  942,  942,  942]),\n",
       "       array([ 911, 1160,  952,  427,  942,  952,  566,  617,  942,  952,  494,\n",
       "        951,  790,  362,  951,  788,  952,  427,   68,  427,  952, 1251,\n",
       "        788,  952,  951,  952,  494,  427,  788,  362,  951]),\n",
       "       array([1302,  617,  287,  287,  617,  952, 1001,  942, 1181,  942,  788,\n",
       "        617,  952, 1229,  788,  427,  287, 1251,  362,  427,  790, 1181,\n",
       "        427,  952, 1251,  790,  362,  617,  952,  566,  617, 1181,  951,\n",
       "        788,  952,  339, 1223,  500,  841]),\n",
       "       ...,\n",
       "       array([1237, 1237, 1237, 1237, 1237, 1237, 1237, 1237, 1237, 1237, 1237,\n",
       "       1237, 1237, 1237, 1237, 1237]),\n",
       "       array([ 201,  617,   68,  617,  386,  951,  952,  790,  951,  952,  915,\n",
       "        427,  386,  617,  788,  362,  952,  617,  942,  952,  719,  617,\n",
       "        566,  427,  494,  952,  810,  951,  790,  952,  790,  617,  952,\n",
       "        994,  617,  942,   34,  942, 1303,  427]),\n",
       "       array([ 810,  427,  287,  287,  617,  951,   68,  952,  427,  287,  287,\n",
       "        951,  287,  952,  287, 1183,  617,  952,  951,   68,  338,  942,\n",
       "        494,  951,  287,  952, 1251,  362,  427, 1251,  951,  287,  952,\n",
       "        413,  123,  952,  362,  427, 1303,  951, 1181, 1251,  362,  951,\n",
       "        287, 1134,  952,  790,  951,  952,  788,  427,  942,  790, 1251,\n",
       "       1183,  617,  952,  362,  427,  952,  173,  617,  413,  427,  952,\n",
       "        427,  287, 1181,  951,  494,  617,  287,  952,  951, 1303,  427,\n",
       "        788, 1181,  617,  952,  951,  952,  790,  617,  566,  951,  287,\n",
       "        952, 1251,  362,  427, 1251,  951,  287,  252])], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling with SMOTE\n",
    "#sm = SMOTE(random_state=42)\n",
    "#X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced data:  (4614,)\n"
     ]
    }
   ],
   "source": [
    "#UNDERSAMPLING\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "#separate classes\n",
    "pos_mask = y_train == 1 \n",
    "y_pos = y_train[pos_mask]\n",
    "X_pos = X_train[pos_mask]\n",
    "\n",
    "neg_mask = y_train == 0 \n",
    "y_neg = y_train[neg_mask]\n",
    "X_neg = X_train[neg_mask]\n",
    "\n",
    "#selects a random sample of negative patterns to match the negative class (most abundant)\n",
    "np.random.seed(42)\n",
    "\n",
    "idx = np.random.randint(y_neg.shape[0], size = y_pos.shape[0])\n",
    "y_sampled = y_neg[idx]\n",
    "X_sampled = X_neg[idx]\n",
    "#concatena a amostra de padrões negativos com os padrões positivos\n",
    "y_train = np.concatenate((y_pos,y_sampled),axis=0)\n",
    "X_train = np.concatenate((X_pos,X_sampled),axis=0)\n",
    "\n",
    "#shuffle\n",
    "indices = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "print('balanced data:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "max_features = features #726 #196921 #corrigir\n",
    "maxlen = 1000\n",
    "batch_size = 32\n",
    "embedding_dims = 100\n",
    "filters = 250\n",
    "kernel_size = 15\n",
    "hidden_dims = 250\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "\n",
    "#variar\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_3_input to have shape (1000,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1dd752199813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train, y_train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=epochs)#,\n\u001b[0m\u001b[1;32m      4\u001b[0m           \u001b[0;31m#validation_data=(X_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_3_input to have shape (1000,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)#,\n",
    "          #validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "y_pred = [0 if x < 0.5 else 1 for x in y_prob]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
